{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Sequential, load_model\n",
    "from tensorflow.python.keras.layers import Dense, Activation\n",
    "from tensorflow.python.keras.layers import LSTM\n",
    "from tensorflow.python.keras.layers import TimeDistributed, Dropout, Embedding\n",
    "from tensorflow.python.keras.optimizers import RMSprop\n",
    "from tensorflow.python.keras.utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 1: Preprocessing Text\n",
    "### Loading corpus\n",
    "\n",
    "Pick text corpora you would like to work on.\n",
    "\n",
    "To chose: pantadeusz, potop, linux, nietzsche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: choose a file\n",
    "path = '../rsc/_.txt'\n",
    "text = open(path).read().lower()\n",
    "print('corpus length:', len(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "print(char_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select data\n",
    "\n",
    "In the chosen corpora we need to define model input - sentences and target - next chracter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    # TODO: select input and target data of the model\n",
    "    sentences.append( _ )\n",
    "    next_chars.append( _ )\n",
    "print('number of sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the result your lists should look like (depending on the text):\n",
    "\n",
    "``` python\n",
    "print(sentences[100:105])\n",
    "['i obmywał mu twarz; chwilami zatrzymywał',\n",
    " 'bmywał mu twarz; chwilami zatrzymywał si',\n",
    " 'wał mu twarz; chwilami zatrzymywał się d',\n",
    " ' mu twarz; chwilami zatrzymywał się dla ',\n",
    " ' twarz; chwilami zatrzymywał się dla poc']\n",
    " \n",
    "print(next_chars[100:105])\n",
    "[' ', 'ę', 'l', 'p', 'z']\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text vectorization\n",
    "\n",
    "Try to represent the text as one hot vectors. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "\n",
    "# TODO: intialize one-hot vectors\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[ _ ]  = _\n",
    "    y[ _ ] = _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the result you should have:\n",
    "\n",
    "``` python\n",
    "print(X[100,...])\n",
    "[[False False False ..., False False False]\n",
    " [False  True False ..., False False False]\n",
    " [False False False ..., False False False]\n",
    " ..., \n",
    " [False False False ..., False False False]\n",
    " [False False False ..., False False False]\n",
    " [False False False ..., False False False]]\n",
    " \n",
    "print(y[100,...])\n",
    "[False  True False False False False False False False False False False\n",
    " False False False False False False False False False False False False\n",
    " False False False False False False False False False False False False\n",
    " False False False False False False False False False False False False\n",
    " False False False False False False False False False False False False\n",
    " False False False False False False]\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 2: Building NN Model\n",
    "\n",
    "Build Neural Network with Keras.\n",
    "\n",
    "### First RNN model\n",
    "\n",
    "Simple RNN model architecture is provided below. To compile the model you need to fill blank spaces first.\n",
    "\n",
    "  * Hint 1: check in the presentation.\n",
    "  * Hint 2:  <span style=\"color:white\"> check the imports in the first block. </span>\n",
    "\n",
    "Backpropagation (RMSprop) is used to minimize loss (crossentropy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TODO: fill blank spaces\n",
    "model = Sequential()\n",
    "model.add( _ (128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation(\" _ \"))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training function and prediction\n",
    "\n",
    "In the function below the model is trained. \n",
    "\n",
    "We use Long Short-Term Memory for recurention. Then probability of the next letter is computed by softmax function:\n",
    "\n",
    "\\begin{equation}\n",
    "P\\left(y = j | x ; W\\right) = \\frac{\\exp(x ^T w_j)}{\\sum_{k=1}^K \\exp(x^T w_k) }\n",
    "\\end{equation}\n",
    "\n",
    "Where $W$ elements are trainable. \n",
    "\n",
    "During prediction we choose:\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{y} = argmax_j P\\left(y = j | x ; W\\right) \n",
    "\\end{equation}\n",
    "\n",
    "In the code below you need add next letter selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run(model, iterations):\n",
    "    for iteration in range(1, iterations):\n",
    "        print('-' * 50)\n",
    "        print('Iteration', iteration+1)\n",
    "        model.fit(X, y, batch_size=128, epochs=1)\n",
    "\n",
    "        start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "\n",
    "        print()\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x, verbose=0)[0]\n",
    "            preds = np.asarray(preds).astype('float64')\n",
    "            \n",
    "            # TODO: How to select next leteter based on preds\n",
    "            next_char = _\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can run training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run(model,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 3: Improve predictions\n",
    "\n",
    "Picking the most likely letter may not be the best solution in text generation (see above).\n",
    "\n",
    "One solution is sampling next letter from softmax distribution:\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{y} \\sim P\\left(y | x ; W\\right) \n",
    "\\end{equation}\n",
    "\n",
    "Please add random sampling in the function **sample_letters**\n",
    "\n",
    "  * Hint: <span style=\"color:white\"> Use np.random.multinomial(1, probabilies, 1). </span>\n",
    "\n",
    "  \n",
    "  \n",
    "### Temperature sampling\n",
    "\n",
    "\n",
    "Softmax distribution may be changed. \n",
    "\n",
    "In temperature sampling we chose additional parameter $\\tau$ (temperature, diversity):\n",
    "\n",
    "\\begin{equation}\n",
    "\\tilde{P_t}\\left(y = j | x ; W\\right) = \\frac{\\exp(\\frac{x ^T w_j}{\\tau})}{\\sum_{k=1}^K \\exp(\\frac{x^T w_k}{\\tau}) }\n",
    "\\end{equation}\n",
    "\n",
    "In general, the $\\tau$ is lower ($\\tau < 1$), the more confident we are about our picks. If it's high the genrated text will be more diverse, but we can make more mistakes.\n",
    "\n",
    "Please add random temperature sampling in the function **sample_letters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_letter(preds, temperature=1.0):\n",
    "    \n",
    "    #TODO: 1. transform output distibution\n",
    "    \n",
    "    #TODO: 2. sample from distribution\n",
    "    \n",
    "    return next_char\n",
    "\n",
    "def run_improved(model, iterations):\n",
    "    for iteration in range(1, iterations+1):\n",
    "        print()\n",
    "        print('-' * 50)\n",
    "        print('Iteration', iteration)\n",
    "        model.fit(X, y, batch_size=128, epochs=1, validation_split=0.2)\n",
    "\n",
    "        start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "\n",
    "        for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "            print()\n",
    "            print('----- diversity:', diversity)\n",
    "\n",
    "            generated = ''\n",
    "            sentence = text[start_index: start_index + maxlen]\n",
    "            generated += sentence\n",
    "            print('----- Generating with seed: \"' + sentence + '\"')\n",
    "            sys.stdout.write(generated)\n",
    "\n",
    "            for i in range(400):\n",
    "                x = np.zeros((1, maxlen, len(chars)))\n",
    "                for t, char in enumerate(sentence):\n",
    "                    x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "                preds = model.predict(x, verbose=0)[0]\n",
    "                preds = np.asarray(preds).astype('float64')\n",
    "                next_char = sample_letter(preds, diversity)\n",
    "\n",
    "                generated += next_char\n",
    "                sentence = sentence[1:] + next_char\n",
    "\n",
    "                sys.stdout.write(next_char)\n",
    "                sys.stdout.flush()\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can run training.\n",
    "\n",
    "\n",
    "(It may take some time to see preditctions after training, becasuse validation is added.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_improved(model,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 4: Improve the model\n",
    "\n",
    "We will make some changes to improve our model.\n",
    "\n",
    "### Embeddings\n",
    "\n",
    "We can use additional layer to transform sparse one-hot vector to dense vectors - embeddings (see presentation).\n",
    "\n",
    "Please add layer to transform one-hot input into embeddings.\n",
    "\n",
    "  * Hint: <span style=\"color:white\"> Use TimeDistributed Dense layer </span>\n",
    "\n",
    "### Batch Normalization\n",
    "\n",
    "We can normalize input to hidden layers in a batch\n",
    "\n",
    "  https://keras.io/layers/normalization/#batchnormalization\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "Please add batch normalization to your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_improved = Sequential()\n",
    "\n",
    "# TODO: Add embedding layer \n",
    "\n",
    "model_improved.add( _ (128))\n",
    "# TODO: Add batch normalization\n",
    "\n",
    "model_improved.add(Dense(len(chars)))\n",
    "model_improved.add(Activation( \"_\" ))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01, decay=10e-5)\n",
    "model_improved.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_improved(model_improved,30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "1. What is the differnce between TimeDistibuted Dense and Embedding layers?\n",
    "\n",
    "2. Why should we use validation?\n",
    "\n",
    "3. How does dropout influence training and validation?\n",
    "\n",
    "### Experiments\n",
    "\n",
    "There are many ways to improve your model:\n",
    "\n",
    "1. Add more dense layers.\n",
    "\n",
    "2. Experiment with batch normalization and dropout.\n",
    "\n",
    "3. Try out other activation functions e.g. relu (keep softmax as output activation):\n",
    "\n",
    "  https://keras.io/activations/\n",
    "\n",
    "4. Use different or more recurent layers:\n",
    "\n",
    "  https://keras.io/layers/recurrent/\n",
    "    \n",
    "5. Experiment with other optimizers (or/and learning rate):\n",
    "  \n",
    "  https://keras.io/optimizers/\n",
    "  \n",
    "\n",
    "\n",
    "### Save your model!\n",
    "\n",
    "When you are excited by your cool new model, you can save it.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_improved.save('../models/my_LM.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained model\n",
    "\n",
    "If you have problems with training and would like to experiment with predictions, you can load pretrained model.\n",
    "\n",
    "You need to work with 'potop.txt' for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model('../models/pretrained_LM.h5')\n",
    "model_improved =  load_model('../models/pretrained_LM.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
