{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASE WEEK  Solutions\n",
    "\n",
    "# Neural Networsk Intro\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import  keras\n",
    "from tensorflow.python.keras.datasets import mnist\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout\n",
    "from tensorflow.python.keras.optimizers import RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAr4AAAK7CAYAAAAUSozGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x158dfd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "random_indices = np.random.randint(0, x_train.shape[0], size=9)\n",
    "\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "for i, ridx in enumerate(random_indices):\n",
    "    fig.add_subplot(3,3,i+1)\n",
    "    plt.title('Label is {label}'.format(label=y_train[ridx]))\n",
    "    plt.imshow(x_train[ridx], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 11s 180us/step - loss: 0.2238 - acc: 0.9317 - val_loss: 0.0920 - val_acc: 0.9714\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 14s 241us/step - loss: 0.0824 - acc: 0.9746 - val_loss: 0.0785 - val_acc: 0.9758\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 11s 184us/step - loss: 0.0541 - acc: 0.9832 - val_loss: 0.0771 - val_acc: 0.9775\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 16s 270us/step - loss: 0.0405 - acc: 0.9870 - val_loss: 0.0818 - val_acc: 0.9789\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 12s 207us/step - loss: 0.0291 - acc: 0.9908 - val_loss: 0.0853 - val_acc: 0.9789\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 18s 292us/step - loss: 0.0236 - acc: 0.9927 - val_loss: 0.0790 - val_acc: 0.9818\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 13s 225us/step - loss: 0.0180 - acc: 0.9945 - val_loss: 0.0894 - val_acc: 0.9806\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 14s 227us/step - loss: 0.0160 - acc: 0.9952 - val_loss: 0.1074 - val_acc: 0.9812\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 12s 207us/step - loss: 0.0141 - acc: 0.9955 - val_loss: 0.1170 - val_acc: 0.9778\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.0127 - acc: 0.9963 - val_loss: 0.1053 - val_acc: 0.9820\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 12s 205us/step - loss: 0.0103 - acc: 0.9968 - val_loss: 0.1011 - val_acc: 0.9835\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 14s 238us/step - loss: 0.0091 - acc: 0.9973 - val_loss: 0.1104 - val_acc: 0.9823\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 17s 281us/step - loss: 0.0085 - acc: 0.9974 - val_loss: 0.1065 - val_acc: 0.9842\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 27s 453us/step - loss: 0.0084 - acc: 0.9977 - val_loss: 0.1321 - val_acc: 0.9797\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 13s 224us/step - loss: 0.0069 - acc: 0.9980 - val_loss: 0.1389 - val_acc: 0.9807\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.0070 - acc: 0.9981 - val_loss: 0.1301 - val_acc: 0.9812\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 18s 298us/step - loss: 0.0054 - acc: 0.9985 - val_loss: 0.1256 - val_acc: 0.9835\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 13s 213us/step - loss: 0.0063 - acc: 0.9983 - val_loss: 0.1313 - val_acc: 0.9836\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 19s 317us/step - loss: 0.0052 - acc: 0.9986 - val_loss: 0.1394 - val_acc: 0.9827\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 18s 293us/step - loss: 0.0064 - acc: 0.9984 - val_loss: 0.1283 - val_acc: 0.9835\n",
      "Test loss: 0.128251\n",
      "Test accuracy: 98.35 %\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss: {:.6f}'.format(score[0]))\n",
    "print('Test accuracy: {:.2f} %'.format(score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_do = Sequential()\n",
    "model_do.add(Dropout(0.2, input_shape=(784,)))\n",
    "model_do.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model_do.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model_do.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "model_do.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 11s 189us/step - loss: 0.2608 - acc: 0.9199 - val_loss: 0.1140 - val_acc: 0.9644\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 24s 406us/step - loss: 0.1090 - acc: 0.9661 - val_loss: 0.0888 - val_acc: 0.9722\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 13s 208us/step - loss: 0.0811 - acc: 0.9743 - val_loss: 0.0756 - val_acc: 0.9763\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 13s 217us/step - loss: 0.0660 - acc: 0.9798 - val_loss: 0.0667 - val_acc: 0.9802\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 13s 212us/step - loss: 0.0557 - acc: 0.9828 - val_loss: 0.0629 - val_acc: 0.9829\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 16s 273us/step - loss: 0.0493 - acc: 0.9851 - val_loss: 0.0684 - val_acc: 0.9805\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 13s 224us/step - loss: 0.0430 - acc: 0.9867 - val_loss: 0.0749 - val_acc: 0.9804\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 12s 204us/step - loss: 0.0381 - acc: 0.9880 - val_loss: 0.0741 - val_acc: 0.9825\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 12s 206us/step - loss: 0.0349 - acc: 0.9887 - val_loss: 0.0706 - val_acc: 0.9825\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 12s 198us/step - loss: 0.0340 - acc: 0.9895 - val_loss: 0.0733 - val_acc: 0.9835\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 13s 220us/step - loss: 0.0308 - acc: 0.9905 - val_loss: 0.0710 - val_acc: 0.9838\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 12s 196us/step - loss: 0.0291 - acc: 0.9916 - val_loss: 0.1015 - val_acc: 0.9793\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 12s 202us/step - loss: 0.0297 - acc: 0.9912 - val_loss: 0.0870 - val_acc: 0.9828\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 13s 213us/step - loss: 0.0274 - acc: 0.9921 - val_loss: 0.0796 - val_acc: 0.9848\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 12s 203us/step - loss: 0.0276 - acc: 0.9927 - val_loss: 0.0935 - val_acc: 0.9819\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 12s 204us/step - loss: 0.0268 - acc: 0.9926 - val_loss: 0.0791 - val_acc: 0.9830\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 13s 209us/step - loss: 0.0253 - acc: 0.9930 - val_loss: 0.0914 - val_acc: 0.9818\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 13s 213us/step - loss: 0.0222 - acc: 0.9935 - val_loss: 0.0944 - val_acc: 0.9826\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 13s 214us/step - loss: 0.0231 - acc: 0.9938 - val_loss: 0.0897 - val_acc: 0.9847\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 13s 215us/step - loss: 0.0223 - acc: 0.9938 - val_loss: 0.0838 - val_acc: 0.9855\n",
      "Test loss: 0.083802\n",
      "Test accuracy: 98.55 %\n",
      "Accuracy improvement: 12.12 %\n"
     ]
    }
   ],
   "source": [
    "model_do.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score_do = model_do.evaluate(x_test, y_test, verbose=0)\n",
    "improve = (score_do[1] - score[1])/(1.0-score[1])\n",
    "print('Test loss: {:.6f}'.format(score_do[0]))\n",
    "print('Test accuracy: {:.2f} %'.format(score_do[1]*100))\n",
    "print('Accuracy improvement: {:.2f} %'.format(improve*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Sequential, load_model\n",
    "from tensorflow.python.keras.layers import Dense, Activation\n",
    "from tensorflow.python.keras.layers import LSTM\n",
    "from tensorflow.python.keras.layers import TimeDistributed, Dropout, Embedding, BatchNormalization\n",
    "from tensorflow.python.keras.optimizers import RMSprop, Adagrad, Adam, SGD\n",
    "from tensorflow.python.keras.utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 1: Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 482805\n",
      "total chars: 54\n"
     ]
    }
   ],
   "source": [
    "path = '../rsc/potop-poczatek.txt'\n",
    "text = open(path, encoding=\"utf-8\").read().lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '\\n', 1: ' ', 2: '!', 3: '(', 4: ')', 5: '*', 6: ',', 7: '-', 8: '.', 9: '1', 10: '8', 11: ':', 12: ';', 13: '?', 14: 'a', 15: 'b', 16: 'c', 17: 'd', 18: 'e', 19: 'f', 20: 'g', 21: 'h', 22: 'i', 23: 'j', 24: 'k', 25: 'l', 26: 'm', 27: 'n', 28: 'o', 29: 'p', 30: 'q', 31: 'r', 32: 's', 33: 't', 34: 'u', 35: 'v', 36: 'w', 37: 'x', 38: 'y', 39: 'z', 40: 'ó', 41: 'ą', 42: 'ć', 43: 'ę', 44: 'ł', 45: 'ń', 46: 'ś', 47: 'ź', 48: 'ż', 49: '–', 50: '—', 51: '”', 52: '„', 53: '…'}\n"
     ]
    }
   ],
   "source": [
    "print(indices_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 160922\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 2: Build the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Right, LSTM and softmax \n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run(model, iterations):\n",
    "    for iteration in range(1, iterations):\n",
    "        print('-' * 50)\n",
    "        print('Iteration', iteration)\n",
    "        model.fit(X, y, batch_size=128, epochs=1)\n",
    "\n",
    "        start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "\n",
    "        print()\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x, verbose=0)[0]\n",
    "            preds = np.asarray(preds).astype('float64')\n",
    "            \n",
    "            # Use argmax\n",
    "            next_index = np.argmax(preds)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Epoch 1/1\n",
      "160922/160922 [==============================] - 287s 2ms/step - loss: 2.2214\n",
      "\n",
      "----- Generating with seed: \"czne. oprócz ludzi zabitych, spostrzeżon\"\n",
      "czne. oprócz ludzi zabitych, spostrzeżony się na przystał się na przystał się na przystał się na przystał się na przystał się na przystał się na przystał się na przystał się na przystał się na przystał się na przystał się na przystał się na przystał się na przystał się na przystał się na przystał się na przystał się na przystał się na przystał się na przystał się na przystał się na przystał się na przystał się na przystał się na przysta\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Epoch 1/1\n",
      "160922/160922 [==============================] - 232s 1ms/step - loss: 1.8635\n",
      "\n",
      "----- Generating with seed: \"stary kiemlicz wraz z synami, z prośbą, \"\n",
      "stary kiemlicz wraz z synami, z prośbą, aby nie miesz przechodzie z podzierał się na powiedzie, aby nie moje za powiedzie i nieprzyjachował się na powiedzie i nieprzyjechał na pod wszystkie za powiedzie i nieprzyjechał na pod wszystkie za powiedzie i nieprzyjechał na pod wszystkie za powiedzie i nieprzyjechał na pod wszystkie za powiedzie i nieprzyjechał na pod wszystkie za powiedzie i nieprzyjechał na pod wszystkie za powiedzie i niepr\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Epoch 1/1\n",
      " 12672/160922 [=>............................] - ETA: 3:27 - loss: 1.7617"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-b07eb9c5f68c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-19-69b914f806dd>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(model, iterations)\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-'\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Iteration'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mstart_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmaxlen\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    580\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 582\u001b[1;33m         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1218\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1220\u001b[1;33m           validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1222\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    243\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m           \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2807\u001b[0m     \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2808\u001b[0m     updated = session.run(\n\u001b[1;32m-> 2809\u001b[1;33m         fetches=fetches, feed_dict=feed_dict, **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2810\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2811\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1140\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1141\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1321\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1312\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[0;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1420\u001b[1;33m             status, run_metadata)\n\u001b[0m\u001b[0;32m   1421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1422\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run(model,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 3: Improve predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_letter(preds, temperature=1.0):\n",
    "\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    \n",
    "\n",
    "    preds = np.random.multinomial(1, preds, 1)\n",
    "    next_index = np.argmax(preds)\n",
    "    next_char = indices_char[next_index]\n",
    "    return next_char\n",
    "\n",
    "def run_improved(model, iterations):\n",
    "    for iteration in range(1, iterations):\n",
    "        print()\n",
    "        print('-' * 50)\n",
    "        print('Iteration', iteration)\n",
    "        model.fit(X, y, batch_size=128, epochs=1, validation_split=0.2)\n",
    "\n",
    "        start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "\n",
    "        for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "            print()\n",
    "            print('----- diversity:', diversity)\n",
    "\n",
    "            generated = ''\n",
    "            sentence = text[start_index: start_index + maxlen]\n",
    "            generated += sentence\n",
    "            print('----- Generating with seed: \"' + sentence + '\"')\n",
    "            sys.stdout.write(generated)\n",
    "\n",
    "            for i in range(400):\n",
    "                x = np.zeros((1, maxlen, len(chars)))\n",
    "                for t, char in enumerate(sentence):\n",
    "                    x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "                preds = model.predict(x, verbose=0)[0]\n",
    "                preds = np.asarray(preds).astype('float64')\n",
    "                next_char = sample_letter(preds, diversity)\n",
    "\n",
    "                generated += next_char\n",
    "                sentence = sentence[1:] + next_char\n",
    "\n",
    "                sys.stdout.write(next_char)\n",
    "                sys.stdout.flush()\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_improved(model,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 4: Improve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_improved = Sequential()\n",
    "model_improved.add(TimeDistributed(Dense(16), input_shape=(maxlen, len(chars) )))\n",
    "model_improved.add(BatchNormalization())\n",
    "model_improved.add(LSTM(64, return_sequences=True))\n",
    "model_improved.add(BatchNormalization())\n",
    "\n",
    "model_improved.add(LSTM(128))\n",
    "\n",
    "model_improved.add(BatchNormalization())\n",
    "model_improved.add(Dense(len(chars)))\n",
    "model_improved.add(Activation('softmax'))\n",
    "\n",
    "optimizer = Adagrad(lr=0.05, decay=10e-5)\n",
    "model_improved.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_improved(model_improved,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_improved.save('my_LM.h5')\n",
    "del model_improved, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model('../models/pretrained_LM.h5')\n",
    "model_improved =  load_model('../models/pretrained_LM.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
